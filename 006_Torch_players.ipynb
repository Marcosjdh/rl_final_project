{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Crear un TorchPlayer\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Recibe el modelo a instanciar como path y juega con el mismo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Pensar como resolver el problema de que solo samplee las válidas\n",
    "- Agregarle la opción de monte carlo tree search (opcional) con las opciones de iterationLimit, timeLimit\n",
    "\n",
    "Si va a agregar MCTS mirar la notebook 007_MCTS.ipnb"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "from players import GreedyPlayer, RandomPlayer\n",
    "from multi_env import make_reversi_vec_env, SelfPlayEnv\n",
    "from boardgame2 import ReversiEnv\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "board_shape = 8\n",
    "n_envs = 10\n",
    "env = make_reversi_vec_env(\n",
    "    SelfPlayEnv, n_envs=n_envs,\n",
    "    env_kwargs={\n",
    "        'board_shape': board_shape,\n",
    "        'LocalPlayer': RandomPlayer\n",
    "    }\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "model = PPO(\n",
    "    ActorCriticPolicy,\n",
    "    env,\n",
    "    verbose=0,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "class TorchPlayer():\n",
    "    # \n",
    "    def __init__(\n",
    "        self, model_path=None, \n",
    "        player=1, board_shape=None, \n",
    "        env=None, flatten_action=False,\n",
    "        deterministic=True, only_valid=True, \n",
    "        mcts=False, iterationLimit=None, timeLimit=None):\n",
    "        if model_path is None:\n",
    "            model_path = '/home/rl_final_project/models/Reversi_PPO_8by8_0.99_0.95_0.0_20_6_masked_actions/best_model.zip'\n",
    "        self.model = PPO.load(model_path)\n",
    "        self.player = player\n",
    "        self.flatten_action = flatten_action\n",
    "        if (env is None) and (board_shape is None):\n",
    "            print(\"board_shape and env can't be both None\")\n",
    "        if env is None:\n",
    "            self.env = self.model.env\n",
    "        if board_shape is None:\n",
    "            self.board_shape = env.board_shape\n",
    "        else:\n",
    "            self.board_shape = board_shape\n",
    "    \n",
    "    def predict(self, board):\n",
    "        board = board * self.player\n",
    "        board_reshape = board[np.newaxis,:,:]\n",
    "        action = self.model.predict(board_reshape)[0]\n",
    "        if self.flatten_action:\n",
    "            return action\n",
    "        else:\n",
    "            return [action // self.board_shape, action % self.board_shape]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Arena"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testear el jugador contra los distintos jugadore"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "def arena_stats(Player_1, Player_2, board_shape, N=500):\n",
    "    \n",
    "    env = ReversiEnv(board_shape=board_shape)\n",
    "    wins_as_first = 0\n",
    "    wins_as_second = 0\n",
    "    plays_as_first = 0\n",
    "    plays_as_second = 0\n",
    "    total_steps = 0\n",
    "    player_1 = Player_1(player=1, board_shape=board_shape, flatten_action=False)\n",
    "    player_2 = Player_2(player=1, board_shape=board_shape, flatten_action=False) # Implementar\n",
    "    for i in range(N):\n",
    "        # Aveces empieza un jugador, a veces el otro\n",
    "        first_player = np.random.choice([-1, 1])\n",
    "        player_1.player = first_player\n",
    "        player_2.player = -first_player\n",
    "        \n",
    "        plays_as_first = plays_as_first + (first_player == 1)\n",
    "        plays_as_second = plays_as_second + (first_player == -1)\n",
    "        \n",
    "        done = False\n",
    "        n_steps = 0\n",
    "        (board, player) = env.reset()\n",
    "        \n",
    "        while not done:\n",
    "            if first_player == player:\n",
    "                action = player_1.predict(board) # Juega el jugador 1\n",
    "            else:\n",
    "                action = player_2.predict(board) # Juega el jugador 2\n",
    "            (board, player), reward, done, info = env.step(action)\n",
    "            n_steps = n_steps + 1\n",
    "        total_steps = total_steps + n_steps\n",
    "        wins_as_first = wins_as_first + (reward == first_player) * (first_player == 1)\n",
    "        wins_as_second = wins_as_second + (reward == first_player) * (first_player == -1)\n",
    "    print(f'Wins as first: {wins_as_first/plays_as_first}')\n",
    "    print(f'Wins as second: {wins_as_second/plays_as_second}')\n",
    "    print(f'Plays as first: {plays_as_first}')\n",
    "    print(f'Plays as second: {plays_as_second}')\n",
    "    print(f'Avg game duration: {total_steps/N}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "arena_stats(TorchPlayer, RandomPlayer, 8, N=2_000)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wins as first: 0.6477157360406092\n",
      "Wins as second: 0.7517241379310344\n",
      "Plays as first: 985\n",
      "Plays as second: 1015\n",
      "Avg game duration: 59.9395\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "arena_stats(TorchPlayer, GreedyPlayer, 8, N=2_000)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wins as first: 0.6420626895854399\n",
      "Wins as second: 0.645895153313551\n",
      "Plays as first: 989\n",
      "Plays as second: 1011\n",
      "Avg game duration: 58.5845\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('myenv': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "3f5c773b913e5a08a20168ef5946a779e1782a0a9eb9fde0852783f88fe2b644"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}